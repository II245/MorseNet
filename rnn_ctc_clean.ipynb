{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import SEQ_LENGTH, FRAMERATE, CHUNK, FFT_SIZE\n",
    "import generate_wav_samples as gen\n",
    "from config import MORSE_CHR\n",
    "import generator_test as gt\n",
    "\n",
    "from tensorflow import keras\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Add, Concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,TimeDistributed, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Reshape, Lambda, Dropout, Bidirectional, Permute, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, SimpleRNN,LSTM\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.callbacks\n",
    "import pickle\n",
    "import Levenshtein\n",
    "import string\n",
    "import pandas as pd\n",
    "import bz2\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(tensorflow.keras.callbacks.Callback):\n",
    "    def __init__(self, run_name, test_func, X):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join('rnn_output', run_name)\n",
    "        self.X = X\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        print('edit distance: ', num)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        \n",
    "        dec_len = 10\n",
    "        print(self.X[0].shape)\n",
    "        for i in range(dec_len):\n",
    "            labels = self.X[1][i:i+1]\n",
    "            print('labels: ', labels_to_text([int(e) for e in labels[0]]))\n",
    "        \n",
    "        word_batch = self.X[0][:dec_len]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print()\n",
    "        print('result lens: ', len(res))\n",
    "        for e in res[:dec_len]:\n",
    "            print(e)\n",
    "        \n",
    "        len_for_cer_count = 5000\n",
    "        word_batch = self.X[0][:len_for_cer_count]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print()\n",
    "        \n",
    "        cers = []\n",
    "        for i, t in enumerate(self.X[1][:len_for_cer_count]):\n",
    "            true = labels_to_text(t)\n",
    "            pred = res[i]\n",
    "\n",
    "            c = cer(true, pred)\n",
    "\n",
    "            cers.append(c)\n",
    "\n",
    "        print(np.mean(cers))\n",
    "            \n",
    "def cer(true, pred):\n",
    "    t = ''.join(true).strip()\n",
    "    p = ''.join(pred).strip()\n",
    "    distance = Levenshtein.distance(t, p)\n",
    "    return distance / len(t) if len(t) > 0 else len(p)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    bc = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    return bc\n",
    "\n",
    "def labels_to_text(i):\n",
    "    return [MORSE_CHR[e] for e in i]\n",
    "\n",
    "def decode_batch2(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    print(np.argmax(out, axis = -1))\n",
    "    return np.argmax(out, axis = -1)\n",
    "\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    r = np.argmax(out, axis=-1)\n",
    "    \n",
    "    res = []\n",
    "    for a in r:\n",
    "        sub_res = []\n",
    "        for i, e in enumerate(a):\n",
    "            if i == 0:\n",
    "                sub_res.append(e)\n",
    "                continue\n",
    "            if (e == a[i-1]):\n",
    "                continue\n",
    "            if (e == len(MORSE_CHR) - 1):\n",
    "                continue\n",
    "            sub_res.append(e)\n",
    "            \n",
    "        sub_res = [e for e in sub_res if e != len(MORSE_CHR) - 1]\n",
    "        sub_res = labels_to_text(sub_res)\n",
    "        res.append(sub_res)\n",
    "            \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set params for trainset generating, or use pregenerated set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = SEQ_LENGTH\n",
    "\n",
    "samples_count = 300000\n",
    "sr = 8000\n",
    "dict_len = len(MORSE_CHR)\n",
    "max_seq_len = 5\n",
    "mel_count = 1\n",
    "mel_len = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = gen.DataGenerator()\n",
    "g = dg.seq_generator(SEQ_LENGTH, FRAMERATE, 1, sr, mel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(set_len, g):\n",
    "    l = np.zeros([set_len, max_seq_len], dtype=np.int32)\n",
    "    X = np.zeros([set_len,  mel_len, mel_count])\n",
    "    input_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "    label_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    for wave, label_indexes, labels, c, mel in tqdm(g):        \n",
    "        if len(labels) > max_seq_len:\n",
    "            continue\n",
    "        if len(labels) == 1 and labels[0] == 0:\n",
    "            continue\n",
    "        if len(labels) == 2 and labels[0] == 0 and labels[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        X[i, :, :] = mel\n",
    "        \n",
    "        l[i, :len(labels)] = labels\n",
    "        input_length[i, :] = mel.shape[0]\n",
    "        \n",
    "        label_length[i, :1] = c\n",
    "        \n",
    "        i+=1\n",
    "        if i == set_len:\n",
    "            break\n",
    "        \n",
    "    return [X, l, input_length, label_length], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f'dataset_{samples_count}_full_wpm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X, l = gt.read_data(samples_count, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with bz2.BZ2File(f'{dataset}.pbz2', 'w') as f:\n",
    "        pickle.dump([X, l], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with bz2.BZ2File(f'{dataset}.pbz2', 'r') as f:\n",
    "        X, l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 161, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, l_val = read_data(200, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def channelPool(x):\n",
    "    return K.max(x,axis=-1)\n",
    "\n",
    "\n",
    "def get_model(optimizer):\n",
    "    input_shape = (mel_len, mel_count)\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    \n",
    "    conv1 = Conv1D(6, 32, strides = 1, padding='same', \n",
    "                        kernel_initializer='he_normal',\n",
    "                       name=f'conv_1', dilation_rate=1)(input_data)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    ac1 = Activation(act)(bn1)\n",
    "        \n",
    "    conv2 = Conv1D(16, 64, strides = 1, padding='same', \n",
    "                       kernel_initializer='he_normal',\n",
    "                       name=f'conv_10', dilation_rate=1)(ac1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "    ac2 = Activation(act)(bn2)\n",
    "    \n",
    "    conv3 = Conv1D(16, 64, strides = 1, padding='same', \n",
    "                       kernel_initializer='he_normal',\n",
    "                       name=f'conv_2', dilation_rate=1)(ac2)\n",
    "    bn3 = BatchNormalization()(conv3)\n",
    "    ac3 = Activation(act)(bn3)\n",
    "    \n",
    "    srnn = SimpleRNN(38, return_sequences=True, kernel_initializer='he_normal')(ac3)\n",
    "    dense1 = Dense(dict_len, kernel_initializer='he_normal', name='dense1')(srnn)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    print(y_pred, labels, input_length, label_length)\n",
    "\n",
    "    loss_out = Lambda(\n",
    "        ctc_lambda_func, output_shape=(1,),\n",
    "        name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "    viz_cb = VizCallback('test', test_func, X_val)\n",
    "    \n",
    "    return model, viz_cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, 161, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 161, 6)            198       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 161, 6)            24        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 161, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv_10 (Conv1D)             (None, 161, 16)           6160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 161, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 161, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 161, 16)           16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 161, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 161, 16)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 161, 38)           2090      \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 161, 38)           1482      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 161, 38)           0         \n",
      "=================================================================\n",
      "Total params: 26,482\n",
      "Trainable params: 26,406\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Tensor(\"softmax_5/Identity:0\", shape=(None, 161, 38), dtype=float32) Tensor(\"the_labels_5:0\", shape=(None, 5), dtype=float32) Tensor(\"input_length_5:0\", shape=(None, 1), dtype=int64) Tensor(\"label_length_5:0\", shape=(None, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "model, viz_cb = get_model(RMSprop(lr=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284105"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, l, validation_split=0.05, batch_size=64, callbacks=[viz_cb], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=RMSprop(lr=0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0,  0,  0],\n",
       "       [19, 32,  0,  0,  0],\n",
       "       [ 9,  4, 22, 33,  0],\n",
       "       [31,  5, 21,  0,  0],\n",
       "       [17,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0],\n",
       "       [25,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0],\n",
       "       [31,  0,  0,  0,  0],\n",
       "       [34, 26, 10,  8,  0]], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e[:10] for e in X]\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join('weights_full_best_model_5.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, 161, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 161, 6)            198       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 161, 6)            24        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 161, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv_10 (Conv1D)             (None, 161, 16)           6160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 161, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 161, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 161, 16)           16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 161, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 161, 16)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 161, 38)           2090      \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 161, 38)           1482      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 161, 38)           0         \n",
      "=================================================================\n",
      "Total params: 26,482\n",
      "Trainable params: 26,406\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Tensor(\"softmax_6/Identity:0\", shape=(None, 161, 38), dtype=float32) Tensor(\"the_labels_6:0\", shape=(None, 5), dtype=float32) Tensor(\"input_length_6:0\", shape=(None, 1), dtype=int64) Tensor(\"label_length_6:0\", shape=(None, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "model, viz_cb = get_model(RMSprop(lr=0.005))\n",
    "model.load_weights('weights_full_best_model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_layer_outputs = K.function([model.layers[0].input],\n",
    "                                  [l.output for l in model.layers[1:] if l.name == 'softmax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Z', 'D', '1', ' '],\n",
       " ['G', '7', ' '],\n",
       " ['6', 'U', ' '],\n",
       " ['0', ' '],\n",
       " ['B', ' '],\n",
       " ['C', 'D', ' '],\n",
       " ['2', 'R', ' '],\n",
       " ['T', '3', 'J', ' '],\n",
       " ['L', '7', 'O', ' '],\n",
       " ['M', 'H', ' ']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode_batch(get_all_layer_outputs, X_val[0])\n",
    "decoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'D', '1', ' ', ' ']\n",
      "['G', '7', ' ', ' ', ' ']\n",
      "['6', 'U', ' ', ' ', ' ']\n",
      "['0', ' ', ' ', ' ', ' ']\n",
      "['B', ' ', ' ', ' ', ' ']\n",
      "['C', 'D', ' ', ' ', ' ']\n",
      "['2', 'R', ' ', ' ', ' ']\n",
      "['T', '3', 'J', ' ', ' ']\n",
      "['L', '7', 'O', ' ', ' ']\n",
      "['M', 'H', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "for i in l_val[:10]:\n",
    "    print(labels_to_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n"
     ]
    }
   ],
   "source": [
    "cers = []\n",
    "for i, t in enumerate(l_val):\n",
    "    true = labels_to_text(t)\n",
    "    pred = decoded[i]\n",
    "    \n",
    "    c = cer(true, pred)\n",
    "    \n",
    "    cers.append(c)\n",
    "    \n",
    "print(np.mean(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "#\n",
    "#print(filters)\n",
    "filters = filters[:,0,:]\n",
    "\n",
    "arr = []\n",
    "df = pd.DataFrame(filters).sort_values([0,1,2,3])\n",
    "a = np.array(df)\n",
    "for e in a:\n",
    "    arr.append(np.array(e))\n",
    "\n",
    "a = np.array(a)\n",
    "#print(a)\n",
    "filters = a\n",
    "#for e in filters:\n",
    "    \n",
    "\n",
    "#filters = np.sort(filters.view('f8,f8,f8,f8'), order=['f1'], axis=0)#.view(np.float)\n",
    "#print(filters)\n",
    "a = filters\n",
    "#a = a[a[:,2].argsort()] # First sort doesn't need to be stable.\n",
    "#a = a[a[:,:,1].argsort(kind='mergesort')]\n",
    "#a = a[a[:,:,0].argsort(kind='mergesort')]\n",
    "filters = a\n",
    "#filters = np.sort(filters, axis=2)\n",
    "# plot first few filters\n",
    "n_filters, ix = 32, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = [filters[i]]\n",
    "    #print(f)\n",
    "    # plot each channel separately\n",
    "    for j in range(1):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(8, 4, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(f, cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D', 'T', '5', 'N', 'N', '5', 'N', 'N', ' ']]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/user/Dropbox/projs/MorseNet/generated/4.wav'\n",
    "path = '/home/user/Downloads/websdr_recording_start_2019-11-11T19_44_23Z_7027.9kHz.wav'\n",
    "sr = 8000\n",
    "wave, sr = librosa.core.load(path, sr=sr)\n",
    "\n",
    "wave = wave[32000*0:1*32000]\n",
    "mel = dg.get_wave_mel_features(wave, sr, 1)\n",
    "\n",
    "to_pred = np.zeros([1,  mel_len, mel_count])\n",
    "to_pred[0,:,:] = mel\n",
    "\n",
    "print(decode_batch(get_all_layer_outputs, to_pred))\n",
    "librosa.display.specshow(mel.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
