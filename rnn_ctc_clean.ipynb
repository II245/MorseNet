{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import SEQ_LENGTH, FRAMERATE, CHUNK, FFT_SIZE\n",
    "import generate_wav_samples as gen\n",
    "from config import MORSE_CHR\n",
    "import generator_test as gt\n",
    "\n",
    "from tensorflow import keras\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,TimeDistributed, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Reshape, Lambda, Dropout, Bidirectional, Permute\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, SimpleRNN,LSTM\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.callbacks\n",
    "import pickle\n",
    "import Levenshtein\n",
    "import string\n",
    "import pandas as pd\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'rnn_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(tensorflow.keras.callbacks.Callback):\n",
    "    def __init__(self, run_name, test_func, X):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.X = X\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        print('edit distance: ', num)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        \n",
    "        dec_len = 10\n",
    "        for i in range(dec_len):\n",
    "            labels = self.X[1][i:i+1]\n",
    "            print('labels: ', labels_to_text([int(e) for e in labels[0]]))\n",
    "        \n",
    "        word_batch = self.X[0][:dec_len]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print('result lens: ', len(res))\n",
    "        for e in res[:dec_len]:\n",
    "            print(e)\n",
    "        \n",
    "        len_for_cer_count = 5000\n",
    "        word_batch = self.X[0][:len_for_cer_count]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print()\n",
    "        \n",
    "        cers = []\n",
    "        for i, t in enumerate(self.X[1][:len_for_cer_count]):\n",
    "            true = labels_to_text(t)\n",
    "            pred = res[i]\n",
    "\n",
    "            c = cer(true, pred)\n",
    "\n",
    "            cers.append(c)\n",
    "\n",
    "        print(np.mean(cers))\n",
    "            \n",
    "def cer(true, pred):\n",
    "    t = ''.join(true).strip()\n",
    "    p = ''.join(pred).strip()\n",
    "    distance = Levenshtein.distance(t, p)\n",
    "    return distance / len(t) if len(t) > 0 else len(p)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    bc = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    return bc\n",
    "\n",
    "def labels_to_text(i):\n",
    "    return [MORSE_CHR[e] for e in i]\n",
    "\n",
    "def decode_batch2(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    print(np.argmax(out, axis = -1))\n",
    "    return np.argmax(out, axis = -1)\n",
    "\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    r = np.argmax(out, axis=-1)\n",
    "    \n",
    "    res = []\n",
    "    for a in r:\n",
    "        sub_res = []\n",
    "        for i, e in enumerate(a):\n",
    "            if i == 0:\n",
    "                sub_res.append(e)\n",
    "                continue\n",
    "            if (e == a[i-1]):\n",
    "                continue\n",
    "            if (e == len(MORSE_CHR) - 1):\n",
    "                continue\n",
    "            sub_res.append(e)\n",
    "            \n",
    "        sub_res = [e for e in sub_res if e != len(MORSE_CHR) - 1]\n",
    "        sub_res = labels_to_text(sub_res)\n",
    "        res.append(sub_res)\n",
    "            \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = SEQ_LENGTH\n",
    "\n",
    "samples_count = 100000\n",
    "sr = 8000\n",
    "dict_len = len(MORSE_CHR)\n",
    "max_seq_len = 5\n",
    "mel_count = 1\n",
    "mel_len = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = gen.DataGenerator()\n",
    "g = dg.seq_generator(SEQ_LENGTH, FRAMERATE, 1, sr, mel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(set_len, g):\n",
    "    l = np.zeros([set_len, max_seq_len], dtype=np.int32)\n",
    "    X = np.zeros([set_len,  mel_len, mel_count])\n",
    "    input_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "    label_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    for wave, label_indexes, labels, c, mel in tqdm(g):        \n",
    "        if len(labels) > max_seq_len:\n",
    "            continue\n",
    "        \n",
    "        X[i, :, :] = mel\n",
    "        \n",
    "        l[i, :len(labels)] = labels\n",
    "        input_length[i, :] = mel.shape[0]\n",
    "        \n",
    "        label_length[i, :1] = c\n",
    "        \n",
    "        i+=1\n",
    "        if i == set_len:\n",
    "            break\n",
    "        \n",
    "    return [X, l, input_length, label_length], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset_100k_digits_15-16wpm'#'dataset_100k_digits.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99991it [11:55, 151.65it/s]Process Process-3:\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/user/Dropbox/projs/MorseNet/generate_wav_samples.py\", line 218, in do_work\n",
      "    time.sleep(0.0100)\n",
      "  File \"/home/user/Dropbox/projs/MorseNet/generate_wav_samples.py\", line 218, in do_work\n",
      "    time.sleep(0.0100)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/user/Dropbox/projs/MorseNet/generate_wav_samples.py\", line 218, in do_work\n",
      "    time.sleep(0.0100)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Dropbox/projs/MorseNet/generate_wav_samples.py\", line 218, in do_work\n",
      "    time.sleep(0.0100)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 325, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 325, in _exit_function\n",
      "    _run_finalizers()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 265, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 325, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 325, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 265, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 265, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 265, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/anaconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    X, l = gt.read_data(samples_count, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "\n",
    "if True:\n",
    "    with open(dataset, 'wb') as f:\n",
    "        pickle.dump([X, l], f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open(dataset, 'rb') as f:\n",
    "        X, l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with bz2.BZ2File(f'{dataset}.pbz2', 'w') as f:\n",
    "        pickle.dump([X, l], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with bz2.BZ2File(f'{dataset}.pbz2', 'r') as f:\n",
    "        X, l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "29it [00:00, 244.30it/s]\u001b[A\n",
      "42it [00:00, 185.86it/s]\u001b[A\n",
      "55it [00:00, 164.13it/s]\u001b[A\n",
      "71it [00:00, 157.69it/s]\u001b[A\n",
      "87it [00:00, 154.28it/s]\u001b[A\n",
      "100it [00:00, 144.67it/s]\u001b[A\n",
      "114it [00:00, 141.87it/s]\u001b[A\n",
      "129it [00:00, 141.33it/s]\u001b[A\n",
      "143it [00:00, 138.87it/s]\u001b[A\n",
      "158it [00:01, 138.99it/s]\u001b[A\n",
      "175it [00:01, 144.64it/s]\u001b[A\n",
      "190it [00:01, 142.17it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "X_val, l_val = read_data(200, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = 64\n",
    "kernel_size = 16\n",
    "pool_size = 32\n",
    "time_dense_size = 32\n",
    "rnn_size = 32\n",
    "minibatch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def channelPool(x):\n",
    "    return K.max(x,axis=-1)\n",
    "\n",
    "\n",
    "def get_model(optimizer):\n",
    "    input_shape = (mel_len, mel_count)\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    \n",
    "    prev = None\n",
    "    for i in range(1):\n",
    "        conv = Conv1D(conv_filters, kernel_size, strides = 1, padding='same', \n",
    "                       activation=act, kernel_initializer='he_normal',\n",
    "                       name=f'conv_{i}')(input_data if prev is None else prev)\n",
    "        \n",
    "        prev = conv\n",
    "    \n",
    "    srnn = SimpleRNN(64, return_sequences=True, kernel_initializer='he_normal')(prev)\n",
    "    dense1 = Dense(dict_len, kernel_initializer='he_normal', name='dense1')(srnn)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    print(y_pred, labels, input_length, label_length)\n",
    "\n",
    "    loss_out = Lambda(\n",
    "        ctc_lambda_func, output_shape=(1,),\n",
    "        name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "    viz_cb = VizCallback('test', test_func, X_val)\n",
    "    \n",
    "    return model, viz_cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, 161, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv1D)              (None, 161, 64)           1088      \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 161, 64)           65600     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 161, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 161, 12)           780       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 161, 12)           0         \n",
      "=================================================================\n",
      "Total params: 75,724\n",
      "Trainable params: 75,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"softmax_2/Identity:0\", shape=(None, 161, 12), dtype=float32) Tensor(\"the_labels_2:0\", shape=(None, 5), dtype=float32) Tensor(\"input_length_2:0\", shape=(None, 1), dtype=int64) Tensor(\"label_length_2:0\", shape=(None, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "model, viz_cb = get_model(RMSprop(lr=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193323"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "89952/90000 [============================>.] - ETA: 0s - loss: 3.9399labels:  ['7', '4', ' ', ' ', ' ']\n",
      "labels:  ['3', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['3', '4', ' ', ' ', ' ']\n",
      "labels:  ['2', ' ', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', ' ', ' ', ' ']\n",
      "labels:  ['4', '4', ' ', ' ', ' ']\n",
      "labels:  ['4', ' ', ' ', ' ', ' ']\n",
      "labels:  ['5', ' ', ' ', ' ', ' ']\n",
      "labels:  ['4', ' ', ' ', ' ', ' ']\n",
      "result lens:  10\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "['4', ' ']\n",
      "\n",
      "0.8833333333333334\n",
      "90000/90000 [==============================] - 129s 1ms/sample - loss: 3.9400 - val_loss: 3.9075\n",
      "Epoch 2/10\n",
      "89984/90000 [============================>.] - ETA: 0s - loss: 3.9212labels:  ['7', '4', ' ', ' ', ' ']\n",
      "labels:  ['3', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['3', '4', ' ', ' ', ' ']\n",
      "labels:  ['2', ' ', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', ' ', ' ', ' ']\n",
      "labels:  ['4', '4', ' ', ' ', ' ']\n",
      "labels:  ['4', ' ', ' ', ' ', ' ']\n",
      "labels:  ['5', ' ', ' ', ' ', ' ']\n",
      "labels:  ['4', ' ', ' ', ' ', ' ']\n",
      "result lens:  10\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "['7', ' ']\n",
      "\n",
      "0.8641666666666667\n",
      "90000/90000 [==============================] - 129s 1ms/sample - loss: 3.9213 - val_loss: 3.9219\n",
      "Epoch 3/10\n",
      "86752/90000 [===========================>..] - ETA: 4s - loss: 3.9103"
     ]
    }
   ],
   "source": [
    "model.fit(X, l, validation_split=0.1, batch_size=32, callbacks=[viz_cb], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_layer_outputs = K.function([model.layers[0].input],\n",
    "                                  [l.output for l in model.layers[1:] if l.name == 'softmax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decode_batch(get_all_layer_outputs, X_val[0])\n",
    "decoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l_val[:10]:\n",
    "    print(labels_to_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cers = []\n",
    "for i, t in enumerate(l_val):\n",
    "    true = labels_to_text(t)\n",
    "    pred = decoded[i]\n",
    "    \n",
    "    c = cer(true, pred)\n",
    "    \n",
    "    cers.append(c)\n",
    "    \n",
    "print(np.mean(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
