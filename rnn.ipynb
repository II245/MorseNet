{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from config import SEQ_LENGTH, FRAMERATE, CHUNK, FFT_SIZE\n",
    "import matplotlib.pyplot as plt\n",
    "import generate_wav_samples as gen\n",
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "from config import MORSE_CHR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers import Input, Dense, Activation,TimeDistributed\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU, SimpleRNN,LSTM\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'rnn_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, run_name, test_func, X):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.X = X\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        print('edit distance: ', num)\n",
    "        \"\"\"\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func,\n",
    "                                       word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j],\n",
    "                                              word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance:'\n",
    "              '%.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "        \"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(\n",
    "            os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        \n",
    "        self.show_edit_distance(256)\n",
    "        \n",
    "        word_batch = self.X[0][:1]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        labels = self.X[1][:1]\n",
    "        print('labels: ', labels_to_text([int(e) for e in labels[0]]))\n",
    "        print('result lens: ', len(res))\n",
    "        for e in res[:3]:\n",
    "            print(e[:15])\n",
    "            \n",
    "\n",
    "def labels_to_text(i):\n",
    "    return [MORSE_CHR[e] for e in i]\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
    "    \"\"\"Runs CTC loss algorithm on each batch element.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: tensor `(samples, max_string_length)`\n",
    "            containing the truth labels.\n",
    "        y_pred: tensor `(samples, time_steps, num_categories)`\n",
    "            containing the prediction, or output of the softmax.\n",
    "        input_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_pred`.\n",
    "        label_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_true`.\n",
    "\n",
    "    # Returns\n",
    "        Tensor with shape (samples,1) containing the\n",
    "            CTC loss of each element.\n",
    "    \"\"\"\n",
    "    label_length = tf.to_int32(tf.squeeze(label_length, axis=-1))\n",
    "    input_length = tf.to_int32(tf.squeeze(input_length, axis=-1))\n",
    "    sparse_labels = tf.to_int32(K.ctc_label_dense_to_sparse(y_true, label_length))\n",
    "\n",
    "    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + K.epsilon())\n",
    "\n",
    "    return tf.expand_dims(K.ctc.ctc_loss(inputs=y_pred,\n",
    "                                       labels=sparse_labels,\n",
    "                                       sequence_length=input_length, ignore_longer_outputs_than_inputs=True), 1)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    bc = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    print(bc)\n",
    "    return bc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = SEQ_LENGTH\n",
    "\n",
    "#SEQ_LENGTH = 24000\n",
    "\n",
    "samples_count = 500\n",
    "sample_len = 80000\n",
    "sr = 8000\n",
    "dict_len = len(MORSE_CHR)\n",
    "max_seq_len = 4\n",
    "mel_count = 1\n",
    "mel_len = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39936"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen.seq_generator(SEQ_LENGTH, FRAMERATE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(set_len):\n",
    "    l = np.zeros([samples_count, max_seq_len])\n",
    "    #l += -1.0\n",
    "    X = np.zeros([samples_count,  mel_len, mel_count])\n",
    "    input_length = np.zeros([samples_count, 1])\n",
    "    label_length = np.zeros([samples_count, 1])\n",
    "\n",
    "    i = 0\n",
    "    for wave, label_indexes, labels, c in tqdm(g):\n",
    "        wave = wave.reshape(SEQ_LENGTH)\n",
    "        wave = librosa.util.normalize(wave)\n",
    "        mel = librosa.feature.melspectrogram(wave, sr=sr, n_fft=500, n_mels=mel_count,hop_length=250)\n",
    "\n",
    "        mel = mel.reshape(mel_len, mel_count)\n",
    "        mel = mel / np.max(mel)\n",
    "        #mel = np.round(mel, decimals=4)\n",
    "\n",
    "        X[i, :, :] = mel\n",
    "        #\n",
    "        labels = [l for l in labels if l != ' ']\n",
    "        #print(labels)\n",
    "        l[i, :len(labels)] = labels\n",
    "        input_length[i, :1] = np.array([float(len(labels))])\n",
    "        label_length[i, :1] = np.array([c])\n",
    "        \n",
    "        #print(labels)\n",
    "        #break\n",
    "        \n",
    "        i+=1\n",
    "        if i == set_len:\n",
    "            break\n",
    "        \n",
    "    return [X, l, input_length, label_length], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "494it [00:04, 122.92it/s]\n"
     ]
    }
   ],
   "source": [
    "X, l = read_data(samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, l_val = read_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(l_val[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 160, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = 32\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 160, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 160, 32)           160       \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 40, 256)           221952    \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 40, 4)             1028      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 40, 4)             0         \n",
      "=================================================================\n",
      "Total params: 223,140\n",
      "Trainable params: 223,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Tensor(\"ctc/ExpandDims:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (mel_len, mel_count)\n",
    "\n",
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "#dense0 = Dense(64, name='dense0', activation=act)(input_data)\n",
    "\n",
    "#\"\"\"\n",
    "inner = Conv1D(conv_filters, kernel_size, padding='same', \n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "mp = MaxPooling1D(pool_size=pool_size, name='max1')(inner)\n",
    "#\"\"\"\n",
    "\n",
    "#dense0 = Dense(64, name='dense0', activation=act)(inner)\n",
    "gru = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru1')(mp)\n",
    "#srnn = SimpleRNN(100, return_sequences=True)(mp)\n",
    "\n",
    "#lstm = LSTM(50, return_sequences=True)(input_data)\n",
    "#srnn = SimpleRNN(50, return_sequences=True)(input_data)\n",
    "#dense2 = Dense(100, kernel_initializer='he_normal', name='dense2')(srnn)\n",
    "dense1 = Dense(dict_len, kernel_initializer='he_normal', name='dense1')(gru)\n",
    "#dense2 = Dense(dict_len, kernel_initializer='he_normal', name='dense2', activation='sigmoid')(dense1)\n",
    "y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "loss_out = Lambda(\n",
    "    ctc_lambda_func, output_shape=(1,),\n",
    "    name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# clipnorm seems to speeds up convergence\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length],\n",
    "              outputs=loss_out)\n",
    "\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "adam = Adam(lr=0.05)\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5) #\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "\n",
    "test_func = K.function([input_data], [y_pred])\n",
    "viz_cb = VizCallback('test', test_func, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 450 samples, validate on 50 samples\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 3s 6ms/step - loss: 2.2192 - val_loss: 2.0420\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "[' ', 'T', ' ']\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 1.9569 - val_loss: 1.8888\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "[' ']\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 1.7393 - val_loss: 1.6170\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 1.3401 - val_loss: 1.1184\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.9448 - val_loss: 0.8229\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7822 - val_loss: 0.7402\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7357 - val_loss: 0.7123\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7088 - val_loss: 0.7021\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6955 - val_loss: 0.7314\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6922 - val_loss: 0.7188\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6845 - val_loss: 0.7142\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6832 - val_loss: 0.7555\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6885 - val_loss: 0.7080\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6799 - val_loss: 0.7212\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6796 - val_loss: 0.6960\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6821 - val_loss: 0.6868\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6750 - val_loss: 0.6957\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6815 - val_loss: 0.6835\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6739 - val_loss: 0.7058\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6736 - val_loss: 0.6885\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6672 - val_loss: 0.6843\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6650 - val_loss: 0.7051\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6717 - val_loss: 0.7088\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6850 - val_loss: 0.6837\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6658 - val_loss: 0.7576\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 2s 6ms/step - loss: 0.6633 - val_loss: 0.7526\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6618 - val_loss: 0.6816\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6678 - val_loss: 0.7141\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6618 - val_loss: 0.7102\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6867 - val_loss: 0.7348\n",
      "edit distance:  256\n",
      "labels:  ['T', ' ', ' ', ' ']\n",
      "result lens:  1\n",
      "['T', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5aba685908>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, l, validation_split=0.1, batch_size=10, callbacks=[viz_cb], epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in l_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
