{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: \n",
    "1. + попробовать пулинг по каналам\n",
    "2. попробовать увеличить алфавит добавить е и т\n",
    "3. чекнуть как свитается цер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from config import SEQ_LENGTH, FRAMERATE, CHUNK, FFT_SIZE\n",
    "import matplotlib.pyplot as plt\n",
    "import generate_wav_samples as gen\n",
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "from config import MORSE_CHR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers import Input, Dense, Activation,TimeDistributed, GlobalMaxPooling1D\n",
    "from keras.layers import Reshape, Lambda, Dropout, Bidirectional, Permute\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU, SimpleRNN,LSTM\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import pickle\n",
    "import Levenshtein\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import generator_test as gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'rnn_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, run_name, test_func, X):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.X = X\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        print('edit distance: ', num)\n",
    "        \"\"\"\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func,\n",
    "                                       word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j],\n",
    "                                              word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance:'\n",
    "              '%.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "        \"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        \n",
    "        #self.show_edit_distance(256)\n",
    "        \n",
    "        dec_len = 10\n",
    "        for i in range(dec_len):\n",
    "            labels = self.X[1][i:i+1]\n",
    "            print('labels: ', labels_to_text([int(e) for e in labels[0]]))\n",
    "        \n",
    "        word_batch = self.X[0][:dec_len]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print('result lens: ', len(res))\n",
    "        for e in res[:dec_len]:\n",
    "            print(e)\n",
    "        \n",
    "        len_for_cer_count = 5000\n",
    "        word_batch = self.X[0][:len_for_cer_count]\n",
    "        res = decode_batch(self.test_func, word_batch)\n",
    "        print()\n",
    "        \n",
    "        cers = []\n",
    "        for i, t in enumerate(self.X[1][:len_for_cer_count]):\n",
    "            true = labels_to_text(t)\n",
    "            pred = res[i]\n",
    "\n",
    "            c = cer(true, pred)\n",
    "\n",
    "            cers.append(c)\n",
    "\n",
    "        print(np.mean(cers))\n",
    "            \n",
    "def cer(true, pred):\n",
    "    t = ''.join(true).strip()\n",
    "    p = ''.join(pred).strip()\n",
    "    distance = Levenshtein.distance(t, p)\n",
    "    return distance / len(t) if len(t) > 0 else len(p)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    bc = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    return bc\n",
    "\n",
    "'''\n",
    "def cer(true, pred):\n",
    "    t = ''.join(true).strip()\n",
    "    p = ''.join(pred).strip()\n",
    "    distance = Levenshtein.distance(t, p)\n",
    "    return distance / len(t)\n",
    "'''\n",
    "\n",
    "def labels_to_text(i):\n",
    "    return [MORSE_CHR[e] for e in i]\n",
    "\n",
    "def decode_batch2(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    print(np.argmax(out, axis = -1))\n",
    "    return np.argmax(out, axis = -1)\n",
    "\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    r = np.argmax(out, axis=-1)\n",
    "    #print('r: ', r)\n",
    "    \n",
    "    res = []\n",
    "    for a in r:\n",
    "        sub_res = []\n",
    "        for i, e in enumerate(a):\n",
    "            #print(i, e)\n",
    "            if i == 0:\n",
    "                sub_res.append(e)\n",
    "                continue\n",
    "            if (e == a[i-1]):\n",
    "                continue\n",
    "            if (e == len(MORSE_CHR) - 1):\n",
    "                continue\n",
    "            sub_res.append(e)\n",
    "            \n",
    "        sub_res = [e for e in sub_res if e != len(MORSE_CHR) - 1]\n",
    "        sub_res = labels_to_text(sub_res)\n",
    "        res.append(sub_res)\n",
    "            \n",
    "    #[e if (i==0 or c != bc[i-1] and c!=3)]\n",
    "    #print('res: ', res)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = SEQ_LENGTH\n",
    "\n",
    "samples_count = 100000\n",
    "sr = 8000\n",
    "dict_len = len(MORSE_CHR)\n",
    "max_seq_len = 5\n",
    "mel_count = 1\n",
    "mel_len = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = gen.DataGenerator()\n",
    "g = dg.seq_generator(SEQ_LENGTH, FRAMERATE, 1, sr, mel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(set_len, g):\n",
    "    l = np.zeros([set_len, max_seq_len], dtype=np.int32)\n",
    "    X = np.zeros([set_len,  mel_len, mel_count])\n",
    "    input_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "    label_length = np.zeros([set_len, 1], dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    for wave, label_indexes, labels, c, mel in tqdm(g):        \n",
    "        if len(labels) > max_seq_len:\n",
    "            continue\n",
    "        \n",
    "        X[i, :, :] = mel\n",
    "        \n",
    "        l[i, :len(labels)] = labels\n",
    "        input_length[i, :] = mel.shape[0]\n",
    "        \n",
    "        label_length[i, :1] = c\n",
    "        \n",
    "        i+=1\n",
    "        if i == set_len:\n",
    "            break\n",
    "        \n",
    "    return [X, l, input_length, label_length], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAH70lEQVR4nO3aS4ydZR3H8d85Z2bagWlKy6WUSyqChhQCaFlojHEjcWFC4gKNKxONCRt1hcF7Ik2MiYKXhdeVhsvCy9LElUs3lRoRgwhaMrSW0hKsbaczc87r4nnnMAwzbUnUf6Kfz6Yn8z7neZ/39n2byQy6rgsA/33D6gUA/L8SYIAiAgxQRIABiggwQBEBBigy82YGDwaDi/zN2mDd527dz7oN27eaZuP2zea71HGXupZsMe5CNl//zGghSXLnXdclSQ4/uZjx5GyS5MBN17RB4y6HXng5SbJztCdJcsuNk2R10k/d5p4sd9PdPPnyqSTJ9duvy665lSTJcNiPmwxy/NxskuTEyrEkyU3z12YwmO5uekT9HvLCuWObHOdrx75v/tokycqkbT96/mhGw/kkyb7tV0znnevXMOpvi1PLo7y0fKw/F5cnSfbv2JbhqN9Dv4DBIPn9K6/2hztOkrxz7+4M5mdedw6yOkmGbQ2Hjpzo513Inbf35/L8cvt3NEyWV9u4Z49mKwduuCqvnGrn6vmzx6Y/y1xb4KHnX0rSrsvNV7W5xyuD6ZrXTtHhUyeTJDdftjdzw7b+STfoz8tgbck5utS+8M/x8eyb39vW329bngwy6Cdc7dbO8/Ek43616+/xtc/t/0tvveyaNxzbaN2j+eyZ4230cFtu37EwnSVJRjPd9PQ+0y5BlsYn844rd7fv7Oivwcwomes/n2/33KHnjk/3ceC2G9uH1XEyN9cvtV3g3z31Yrp+jwf2X9+2zc4mS0v9uH4BSyvTZ+E164/3Yh3YaKvne7PvbHzGL9akC9lszW9Yw8td1139htnfzN8BtwBv3ezBuh2uXYB2m3Wv295tcbAbt28236WOu9S1rLfptsHgtRumr1q3VpINrt357iTJ4qmvJkn2XPFATp4+nCSZPPqp9t3TS5m5/8dJknt3fzZJ8stHTmdy4kybZNL2df7IcrrWlCz84Ikkyddv/VLuu6mFY9u2tvHsubk88scW8u8tHkyS/OSuz2XbqH/4V9tDOxp0OTdun+//w8ELnqMf3vH5JMnxpTb+i39+KLsWbmv7ePu9SZLTq8PcMN8ideW280mSx47szLePtLn37HxXkuTw+9+W7QttrSv9fDNzk+x54tdJktXVVoGlL9+Xmf39/dm/jLqTZzK4vD3cw098f3qOX/zLZ9pan/tbG79zR7L49zbunoeyldVvfCy/eLy9HD986GvTnw1vbC+V0Ue+kyT54K4H8rNPvpAkObPY4jya7aYvkF0/fSxJ8vO7H8y+y9t1O7vanotXV2YzP2oDDz7djvs3r34rP7rjC0mS3XMtsIvnZjM7fXG16/CV5x7OeNzmW3+PDwbtvA37l+Djd3167TaZ2t2/mJPkA7/9ZpJk4bJb8qd73tOOc9yO44orz01fKu/7VRv/1CuP5h8f/2j7znvbuciencn17UWcvy62c/Chh6f7GD/93fbhxKl0b7mhfV5ua9h+64OZ9DfvyuF2PSZ792b49DNt3Eob1z17bPosrOnSXXIHNtrq+d7sOxuf/4s16ULWX6P1bXj9GlYOdV1398bv+hUEQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQZNB13aUPHgxOJDnyn1sOwP+kfV3XXb3xh28qwAD8+/gVBEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQJF/ATEJmtjEFFUaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "wave, sr = librosa.core.load('/home/user/Dropbox/projs/MorseNet/generated/0.wav', sr=8000)\n",
    "#wave, sr = librosa.core.load('/home/user/Downloads/websdr_recording_start_2019-06-15T21_33_35Z_7017.3kHz.wav', sr=8000)\n",
    "\n",
    "\n",
    "#wave = wave[:33000]\n",
    "#wave = wave.reshape(SEQ_LENGTH)\n",
    "wave = librosa.util.normalize(wave)\n",
    "mel = librosa.feature.melspectrogram(wave, sr=sr, n_fft=250, n_mels=1, hop_length=200, power=2)\n",
    "#mel = np.where(mel<0.1, 0, mel)\n",
    "\n",
    "#print(mel)\n",
    "def smooth(mel, w):\n",
    "    for i in range(mel.shape[0]):\n",
    "        print(mel.shape[1] // w)\n",
    "        steps = mel.shape[1] // w\n",
    "        for j in range(steps):\n",
    "            if (j+1)*w > mel.shape[1]:\n",
    "                continue\n",
    "\n",
    "            window = mel[i, j*w:(j+1)*w]\n",
    "            #print(window)\n",
    "\n",
    "            window = window / np.linalg.norm(window)\n",
    "            #print(window)\n",
    "            #print(np.linalg.norm(window))\n",
    "\n",
    "\n",
    "            #window = window / np.max(window)\n",
    "\n",
    "            #print(window)\n",
    "\n",
    "            #window = np.normalize(window)\n",
    "            mel[i, j*w:(j+1)*w] = window\n",
    "    return mel\n",
    "#mel = smooth(mel, 30)\n",
    "#mel = smooth(mel, 40)\n",
    "\n",
    "#mel = rolling_window(mel, 160).max(axis=1)\n",
    "#print(mel)\n",
    "\n",
    "#mel = scipy.ndimage.filters.maximum_filter1d(mel, 2)\n",
    "#mel = np.max(mel) \n",
    "#mel = np.where(mel<1, 0, mel)\n",
    "#mel = np.where(mel>1, 1, mel)\n",
    "#to_pred = np.zeros([1,  mel_len, mel_count])\n",
    "#to_pred[0,:,:] = mel\n",
    "\n",
    "#print(decode_batch(get_all_layer_outputs, to_pred))\n",
    "\n",
    "plt.figure()\n",
    "#fig, ax = plt.subplots(1, sharex=True, figsize=(50,100))\n",
    "#plt.subplot(figsize=(50,100))\n",
    "librosa.display.specshow(mel, sr=8000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X, l = gt.read_data(samples_count, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset_100k_digits_te.pickle'#'dataset_100k_digits.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(dataset, 'wb') as f:\n",
    "        pickle.dump([X, l], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open(dataset, 'rb') as f:\n",
    "        X, l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128800000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[0].size * X[0].itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:03, 83.26it/s] \n"
     ]
    }
   ],
   "source": [
    "X_val, l_val = read_data(200, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = 64\n",
    "kernel_size = 16\n",
    "pool_size = 32\n",
    "time_dense_size = 32\n",
    "rnn_size = 32\n",
    "minibatch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def channelPool(x):\n",
    "    return K.max(x,axis=-1)\n",
    "\n",
    "\n",
    "def get_model(optimizer):\n",
    "    input_shape = (mel_len, mel_count)\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    \n",
    "    prev = None\n",
    "    for i in range(2):\n",
    "        conv = Conv1D(conv_filters, kernel_size, strides = 1, padding='same', \n",
    "                       activation=act, kernel_initializer='he_normal',\n",
    "                       name=f'conv_{i}')(input_data if prev is None else prev)\n",
    "        \n",
    "\n",
    "        \n",
    "        #pm1 = Permute((2, 1))(inner)\n",
    "        #mp = MaxPooling1D(pool_size=pool_size, name=f'max_{i}', strides=2, padding='same', )(pm1)\n",
    "        #pm2 = Permute((2, 1))(mp)\n",
    "        #mp = MaxPooling1D(pool_size=pool_size, name=f'max_{i}', strides=1, padding='same', )(inner)\n",
    "        #ll = Lambda(channelPool)(inner)#, output_shape=optionalInTensorflow\n",
    "        prev = conv\n",
    "    \n",
    "    conv10 = Conv1D(4, 16, padding='same', \n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name=f'conv_10')(input_data)\n",
    "    \n",
    "    conv11 = Conv1D(6, 16, padding='same', \n",
    "           activation=act, kernel_initializer='he_normal',\n",
    "           name=f'conv_11')(conv10)\n",
    "    \n",
    "    conv12 = Conv1D(8, 32, padding='same', \n",
    "       activation=act, kernel_initializer='he_normal',\n",
    "       name=f'conv_12')(conv11)\n",
    "    \n",
    "    conv13 = Conv1D(4, 16, padding='same', \n",
    "       activation=act, kernel_initializer='he_normal',\n",
    "       name=f'conv_13')(conv12)\n",
    "        \n",
    "    conv2 = Conv1D(1, 16, padding='same', \n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name=f'conv_2_{i}')(prev)\n",
    "    \n",
    "    #gru2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(mp)\n",
    "    #gru = GRU(32, return_sequences=True, kernel_initializer='he_normal', name='gru1',unroll=True)(mp)\n",
    "    #dense0 = Dense(16, kernel_initializer='he_normal', name='dense0')(mp)\n",
    "    \n",
    "    srnn = SimpleRNN(64, return_sequences=True, kernel_initializer='he_normal')(conv13)\n",
    "    #srnn2 = SimpleRNN(32, return_sequences=True, kernel_initializer='he_normal',)(srnn)\n",
    "    #srnn3 = SimpleRNN(32, return_sequences=True, kernel_initializer='he_normal',)(srnn2)\n",
    "    \n",
    "    \n",
    "    #lstm = LSTM(32, return_sequences=True, kernel_initializer='he_normal', name='lstm',unroll=True)(mp)\n",
    "    #lstm2 = LSTM(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm)\n",
    "    \n",
    "    #lstm2 = LSTM(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm)\n",
    "    #lstm3 = LSTM(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='lstm3')(lstm2)\n",
    "\n",
    "    #dense2 = Dense(128, kernel_initializer='he_normal', name='dense2')(gru)\n",
    "\n",
    "    #dpo = Dropout(0.01, name='do1')(gru)\n",
    "    dense1 = Dense(dict_len, kernel_initializer='he_normal', name='dense1')(srnn)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    print(y_pred, labels, input_length, label_length)\n",
    "\n",
    "    loss_out = Lambda(\n",
    "        ctc_lambda_func, output_shape=(1,),\n",
    "        name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "    viz_cb = VizCallback('test', test_func, X_val)\n",
    "    \n",
    "    return model, viz_cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 161, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv_10 (Conv1D)             (None, 161, 4)            68        \n",
      "_________________________________________________________________\n",
      "conv_11 (Conv1D)             (None, 161, 6)            390       \n",
      "_________________________________________________________________\n",
      "conv_12 (Conv1D)             (None, 161, 8)            1544      \n",
      "_________________________________________________________________\n",
      "conv_13 (Conv1D)             (None, 161, 4)            516       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 161, 64)           4416      \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 161, 8)            520       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 161, 8)            0         \n",
      "=================================================================\n",
      "Total params: 7,454\n",
      "Trainable params: 7,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"softmax/truediv:0\", shape=(?, 161, 8), dtype=float32) Tensor(\"the_labels:0\", shape=(?, 5), dtype=float32) Tensor(\"input_length:0\", shape=(?, 1), dtype=int64) Tensor(\"label_length:0\", shape=(?, 1), dtype=int64)\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4253: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, viz_cb = get_model(RMSprop(lr=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "90000/90000 [==============================] - 152s 2ms/step - loss: 1.1485 - val_loss: 1.1361\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ']\n",
      "['9', '8', ' ', ' ']\n",
      "['1', '9', ' ', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.185\n",
      "Epoch 2/10\n",
      "90000/90000 [==============================] - 152s 2ms/step - loss: 1.1309 - val_loss: 1.1170\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.17666666666666664\n",
      "Epoch 3/10\n",
      "90000/90000 [==============================] - 156s 2ms/step - loss: 1.1206 - val_loss: 1.1119\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.18041666666666664\n",
      "Epoch 4/10\n",
      "90000/90000 [==============================] - 157s 2ms/step - loss: 1.1136 - val_loss: 1.1152\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['0', ' ', '0', ' ']\n",
      "['0', ' ', ' ']\n",
      "['T', '0', ' ', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ', ' ']\n",
      "['0', '9', ' ']\n",
      "[' ']\n",
      "['0', ' ', '8', ' ', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.20291666666666663\n",
      "Epoch 5/10\n",
      "90000/90000 [==============================] - 159s 2ms/step - loss: 1.1148 - val_loss: 1.1342\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ']\n",
      "['8', ' ', 'T', ' ']\n",
      "['9', '8', ' ']\n",
      "['0', '9', ' ', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ']\n",
      "['T', 'E', ' ']\n",
      "\n",
      "0.18583333333333332\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 147s 2ms/step - loss: 1.1164 - val_loss: 1.1122\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['0', ' ', '0', ' ']\n",
      "['0', ' ']\n",
      "['T', '0', ' ', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ', ' ']\n",
      "['0', '9', ' ']\n",
      "[' ']\n",
      "['0', ' ', '8', ' ', ' ']\n",
      "['T', 'E', ' ']\n",
      "\n",
      "0.21416666666666664\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 148s 2ms/step - loss: 1.1213 - val_loss: 1.1163\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.18458333333333332\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 149s 2ms/step - loss: 1.1078 - val_loss: 1.1028\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.17541666666666664\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 148s 2ms/step - loss: 1.0981 - val_loss: 1.0992\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ', ' ']\n",
      "['E', 'T', 'E', ' ']\n",
      "\n",
      "0.17958333333333332\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 148s 2ms/step - loss: 1.0947 - val_loss: 1.1104\n",
      "labels:  ['8', '8', ' ', ' ', ' ']\n",
      "labels:  ['0', ' ', '1', ' ', ' ']\n",
      "labels:  ['1', ' ', ' ', ' ', ' ']\n",
      "labels:  ['T', '1', ' ', ' ', ' ']\n",
      "labels:  ['8', ' ', 'T', ' ', ' ']\n",
      "labels:  ['9', '8', ' ', ' ', ' ']\n",
      "labels:  ['1', '9', ' ', ' ', ' ']\n",
      "labels:  [' ', ' ', ' ', ' ', ' ']\n",
      "labels:  ['1', ' ', '8', ' ', ' ']\n",
      "labels:  ['9', 'T', 'E', ' ', ' ']\n",
      "result lens:  10\n",
      "['8', '8', ' ', ' ']\n",
      "['1', ' ', '1', ' ']\n",
      "['1', ' ']\n",
      "['T', '1', ' ', ' ']\n",
      "['8', ' ', 'T', ' ']\n",
      "['9', '8', ' ']\n",
      "['1', '9', ' ']\n",
      "[' ']\n",
      "['1', ' ', '8', ' ', ' ']\n",
      "['9', 'T', 'E', ' ']\n",
      "\n",
      "0.17416666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6f54f0860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, l, validation_split=0.1, batch_size=32, callbacks=[viz_cb], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=RMSprop(lr=0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 161, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 161, 512)          16896     \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 161, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 161, 32)           69760     \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 161, 8)            264       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 161, 8)            0         \n",
      "=================================================================\n",
      "Total params: 86,920\n",
      "Trainable params: 86,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"softmax/truediv:0\", shape=(?, 161, 8), dtype=float32) Tensor(\"the_labels:0\", shape=(?, 5), dtype=float32) Tensor(\"input_length:0\", shape=(?, 1), dtype=int64) Tensor(\"label_length:0\", shape=(?, 1), dtype=int64)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "best_model, viz_cb = get_model()\n",
    "best_model.load_weights('rnn_output/test/weights99.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_layer_outputs = K.function([model.layers[0].input],\n",
    "                                  [l.output for l in model.layers[1:] if l.name == 'softmax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7', '7', ' '],\n",
       " ['B', 'Y', ' '],\n",
       " ['R', 'L', 'V', '7', ' '],\n",
       " ['Z', ' ', 'U', 'C', ' '],\n",
       " ['E', 'A', '1', ' '],\n",
       " ['K', ' ', 'B', 'L', ' '],\n",
       " ['W', '5', 'B', 'S', 'S', 'S', ' '],\n",
       " ['7', ' '],\n",
       " ['I', 'I', 'M', '9', ' '],\n",
       " ['X', 'B', 'U', 'U', 'U', ' ']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode_batch(get_all_layer_outputs, X_val[0])\n",
    "decoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6', '2', ' ', ' ', ' ', ' ']\n",
      "['B', 'P', 'Y', 'C', ' ', ' ']\n",
      "['R', 'L', 'V', '7', ' ', ' ']\n",
      "['Z', ' ', 'U', 'C', ' ', ' ']\n",
      "['D', 'E', 'J', '1', ' ', ' ']\n",
      "['K', ' ', 'B', ' ', 'L', ' ']\n",
      "['0', 'W', 'B', 'S', 'S', ' ']\n",
      "['7', '3', 'C', '6', ' ', ' ']\n",
      "['I', 'T', 'M', 'S', '9', ' ']\n",
      "['X', 'B', 'U', 'M', 'U', ' ']\n"
     ]
    }
   ],
   "source": [
    "for i in l_val[:10]:\n",
    "    print(labels_to_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.393275\n"
     ]
    }
   ],
   "source": [
    "cers = []\n",
    "for i, t in enumerate(l_val):\n",
    "    true = labels_to_text(t)\n",
    "    pred = decoded[i]\n",
    "    \n",
    "    c = cer(true, pred)\n",
    "    \n",
    "    cers.append(c)\n",
    "    \n",
    "print(np.mean(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8f89ed88188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'/home/user/Downloads/websdr_recording_start_2019-06-15T21_33_16Z_7017.3kHz.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/user/Dropbox/projs/MorseNet/generated/0.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m39936\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wave_mel_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "'/home/user/Downloads/websdr_recording_start_2019-06-15T21_33_16Z_7017.3kHz.wav'\n",
    "\n",
    "wave, sr = librosa.core.load('/home/user/Dropbox/projs/MorseNet/generated/0.wav', sr=8000)\n",
    "wave = wave[:39936]\n",
    "mel = get_wave_mel_features(wave)\n",
    "\n",
    "\n",
    "to_pred = np.zeros([1,  mel_len, mel_count])\n",
    "to_pred[0,:,:] = mel\n",
    "\n",
    "print(decode_batch(get_all_layer_outputs, to_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "librosa.display.specshow(mel.T)\n",
    "plt.show()\n",
    "#raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ', 'A', 'F', 'E']]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wave, sr = librosa.core.load('/home/user/Downloads/websdr_recording_start_2019-06-15T21_33_16Z_7017.3kHz.wav', sr=8000)\n",
    "wave = wave[:39936]\n",
    "mel = get_wave_mel_features(wave)\n",
    "\n",
    "to_pred = np.zeros([1,  mel_len, mel_count])\n",
    "to_pred[0,:,:] = mel\n",
    "\n",
    "print(decode_batch(get_all_layer_outputs, to_pred))\n",
    "\n",
    "librosa.display.specshow(mel.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wave, sr = librosa.core.load('/home/user/Dropbox/projs/MorseNet/generated/0.wav', sr=8000)\n",
    "wave = wave[:39936]\n",
    "mel = get_wave_mel_features(wave)\n",
    "\n",
    "to_pred = np.zeros([1,  mel_len, mel_count])\n",
    "to_pred[0,:,:] = mel\n",
    "\n",
    "#print(decode_batch(get_all_layer_outputs, to_pred))\n",
    "\n",
    "librosa.display.specshow(mel.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
